#
# Copyright 2018 Confluent Inc.
#
# Licensed under the Confluent Community License (the "License"); you may not use
# this file except in compliance with the License.  You may obtain a copy of the
# License at
#
# http://www.confluent.io/confluent-community-license
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OF ANY KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations under the License.
#

# A simple example that copies from a topic to a SQLite database.
# The first few settings are required for all connectors:
# a name, the connector class to run, and the maximum number of tasks to create:
name=test-sink
connector.class=com.gallop.connect.logminer.JdbcSinkConnector
tasks.max=1

# The topics to consume from - required for sink connectors like this one
topics=testdb.events

# Configuration specific to the JDBC sink connector.
# We want to connect to a SQLite database stored in the file test.db and auto-create tables.

connection.url=jdbc:oracle:thin:@192.168.0.117:1521:orcl
connection.user=cdcuser
connection.password=cdcuser
batch.size=50
auto.create=true

# log error context along with application logs, but do not include configs and messages
#ErrantRecordReporter 要生效的配置：
errors.log.enable=true
errors.log.include.messages=false

# produce error context into the Kafka topic，记录错误消息的死信队列，需要预先创建好topic
errors.deadletterqueue.topic.name=my-connector-errors

# Tolerate all errors.
errors.tolerance=all

# Define when identifiers should be quoted in DDL and DML statements.
# The default is 'always' to maintain backward compatibility with prior versions.
# Set this to 'never' to avoid quoting fully-qualified or simple table and column names.
#quote.sql.identifiers=always

#源表空间和目标表空间的映射，格式： 源表空间1:目标表空间1,源表空间2:目标表空间2
tablespace.sourceSinkMap=LOGMINER:RMYY,USERCENTER:DSS
